{"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9144106,"sourceType":"datasetVersion","datasetId":5522924},{"sourceId":9144186,"sourceType":"datasetVersion","datasetId":5522978}],"dockerImageVersionId":30747,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install --upgrade transformers\n!pip install flash_attn\n!pip install pdfplumber\n!pip install faiss-cpu\n!pip install sentence_transformers\n!pip install numpy\n!pip install datasets\n!pip install huggingface_hub\n!pip install nltk","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XluK8LZ6Sslu","outputId":"dfaa51e2-c45a-464f-d3b3-5f3822422a8d","execution":{"iopub.status.busy":"2024-08-10T04:48:40.290167Z","iopub.execute_input":"2024-08-10T04:48:40.290518Z","iopub.status.idle":"2024-08-10T04:51:06.580918Z","shell.execute_reply.started":"2024-08-10T04:48:40.290489Z","shell.execute_reply":"2024-08-10T04:51:06.579641Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.42.3)\nCollecting transformers\n  Downloading transformers-4.44.0-py3-none-any.whl.metadata (43 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.13.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.23.4)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.12.25)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.32.3)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.3)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.19.1)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.4)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.5.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.7.4)\nDownloading transformers-4.44.0-py3-none-any.whl (9.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m75.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: transformers\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.42.3\n    Uninstalling transformers-4.42.3:\n      Successfully uninstalled transformers-4.42.3\nSuccessfully installed transformers-4.44.0\nCollecting flash_attn\n  Downloading flash_attn-2.6.3.tar.gz (2.6 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m42.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from flash_attn) (2.1.2)\nCollecting einops (from flash_attn)\n  Downloading einops-0.8.0-py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->flash_attn) (3.13.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch->flash_attn) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->flash_attn) (1.13.0)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->flash_attn) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->flash_attn) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch->flash_attn) (2024.5.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->flash_attn) (2.1.3)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->flash_attn) (1.3.0)\nDownloading einops-0.8.0-py3-none-any.whl (43 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.2/43.2 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: flash_attn\n  Building wheel for flash_attn (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for flash_attn: filename=flash_attn-2.6.3-cp310-cp310-linux_x86_64.whl size=186973264 sha256=a317a6656be86fa5f583be039c38408258633a21c9de5d5623e11486d6a5541c\n  Stored in directory: /root/.cache/pip/wheels/7e/e3/c3/89c7a2f3c4adc07cd1c675f8bb7b9ad4d18f64a72bccdfe826\nSuccessfully built flash_attn\nInstalling collected packages: einops, flash_attn\nSuccessfully installed einops-0.8.0 flash_attn-2.6.3\nCollecting pdfplumber\n  Downloading pdfplumber-0.11.3-py3-none-any.whl.metadata (41 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.0/42.0 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting pdfminer.six==20231228 (from pdfplumber)\n  Downloading pdfminer.six-20231228-py3-none-any.whl.metadata (4.2 kB)\nRequirement already satisfied: Pillow>=9.1 in /opt/conda/lib/python3.10/site-packages (from pdfplumber) (9.5.0)\nCollecting pypdfium2>=4.18.0 (from pdfplumber)\n  Downloading pypdfium2-4.30.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (48 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.5/48.5 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: charset-normalizer>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from pdfminer.six==20231228->pdfplumber) (3.3.2)\nRequirement already satisfied: cryptography>=36.0.0 in /opt/conda/lib/python3.10/site-packages (from pdfminer.six==20231228->pdfplumber) (41.0.7)\nRequirement already satisfied: cffi>=1.12 in /opt/conda/lib/python3.10/site-packages (from cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (1.16.0)\nRequirement already satisfied: pycparser in /opt/conda/lib/python3.10/site-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (2.21)\nDownloading pdfplumber-0.11.3-py3-none-any.whl (59 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.2/59.2 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pdfminer.six-20231228-py3-none-any.whl (5.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m77.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading pypdfium2-4.30.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m71.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: pypdfium2, pdfminer.six, pdfplumber\nSuccessfully installed pdfminer.six-20231228 pdfplumber-0.11.3 pypdfium2-4.30.0\nCollecting faiss-cpu\n  Downloading faiss_cpu-1.8.0.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.7 kB)\nRequirement already satisfied: numpy<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from faiss-cpu) (1.26.4)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from faiss-cpu) (21.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->faiss-cpu) (3.1.1)\nDownloading faiss_cpu-1.8.0.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (27.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.0/27.0 MB\u001b[0m \u001b[31m64.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: faiss-cpu\nSuccessfully installed faiss-cpu-1.8.0.post1\nCollecting sentence_transformers\n  Downloading sentence_transformers-3.0.1-py3-none-any.whl.metadata (10 kB)\nRequirement already satisfied: transformers<5.0.0,>=4.34.0 in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (4.44.0)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (4.66.4)\nRequirement already satisfied: torch>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (2.1.2)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (1.26.4)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (1.2.2)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (1.11.4)\nRequirement already satisfied: huggingface-hub>=0.15.1 in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (0.23.4)\nRequirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (9.5.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence_transformers) (3.13.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence_transformers) (2024.5.0)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence_transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence_transformers) (6.0.1)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence_transformers) (2.32.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence_transformers) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (1.13.0)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (3.1.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.34.0->sentence_transformers) (2023.12.25)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.34.0->sentence_transformers) (0.4.3)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.34.0->sentence_transformers) (0.19.1)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence_transformers) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence_transformers) (3.2.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface-hub>=0.15.1->sentence_transformers) (3.1.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.11.0->sentence_transformers) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (2024.7.4)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.11.0->sentence_transformers) (1.3.0)\nDownloading sentence_transformers-3.0.1-py3-none-any.whl (227 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.1/227.1 kB\u001b[0m \u001b[31m88.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: sentence_transformers\nSuccessfully installed sentence_transformers-3.0.1\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (1.26.4)\nRequirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.20.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets) (3.13.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (1.26.4)\nRequirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (16.1.0)\nRequirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets) (0.6)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.2.2)\nRequirement already satisfied: requests>=2.32.2 in /opt/conda/lib/python3.10/site-packages (from datasets) (2.32.3)\nRequirement already satisfied: tqdm>=4.66.3 in /opt/conda/lib/python3.10/site-packages (from datasets) (4.66.4)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2024.5.0,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.5.0,>=2023.1.0->datasets) (2024.5.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.1)\nRequirement already satisfied: huggingface-hub>=0.21.2 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.23.4)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (6.0.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.2->datasets) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (2024.7.4)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.4)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\nRequirement already satisfied: huggingface_hub in /opt/conda/lib/python3.10/site-packages (0.23.4)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (3.13.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (2024.5.0)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (6.0.1)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (2.32.3)\nRequirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (4.66.4)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface_hub) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub) (2024.7.4)\nRequirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (3.2.4)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from nltk) (1.16.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"from huggingface_hub import login\n\nhf_token = \"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\"\nlogin(hf_token)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"F5UdVDDr-vjI","outputId":"fa9ed630-8dad-4de6-b214-5013ef780dfb","execution":{"iopub.status.busy":"2024-08-10T04:51:06.583350Z","iopub.execute_input":"2024-08-10T04:51:06.583760Z","iopub.status.idle":"2024-08-10T04:51:07.170734Z","shell.execute_reply.started":"2024-08-10T04:51:06.583725Z","shell.execute_reply":"2024-08-10T04:51:07.169573Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\nToken is valid (permission: fineGrained).\nYour token has been saved to /root/.cache/huggingface/token\nLogin successful\n","output_type":"stream"}]},{"cell_type":"code","source":"import pdfplumber\nfrom transformers import AutoTokenizer, AutoModel, pipeline, AutoModelForCausalLM\nimport faiss\nimport numpy as np\nfrom sentence_transformers import SentenceTransformer\nimport nltk\nfrom nltk import sent_tokenize\nimport os\nimport torch","metadata":{"id":"lF01KbfHuf4z","execution":{"iopub.status.busy":"2024-08-10T04:51:07.171913Z","iopub.execute_input":"2024-08-10T04:51:07.172267Z","iopub.status.idle":"2024-08-10T04:51:23.913513Z","shell.execute_reply.started":"2024-08-10T04:51:07.172240Z","shell.execute_reply":"2024-08-10T04:51:23.912573Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"2024-08-10 04:51:11.822452: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-08-10 04:51:11.822570: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-08-10 04:51:11.952017: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"nltk.download('punkt')","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lm6cb0R6UL_Z","outputId":"b39d1765-926c-422f-da20-43355243009b","execution":{"iopub.status.busy":"2024-08-10T04:51:23.915425Z","iopub.execute_input":"2024-08-10T04:51:23.916011Z","iopub.status.idle":"2024-08-10T04:51:24.037416Z","shell.execute_reply.started":"2024-08-10T04:51:23.915983Z","shell.execute_reply":"2024-08-10T04:51:24.036587Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n","output_type":"stream"},{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\ntokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\nmodel = AutoModel.from_pretrained(\"bert-base-uncased\").to(device)\n\ndef extract_text_from_pdf(pdf_path):\n    \"\"\"Extract text from a single PDF file.\"\"\"\n    with pdfplumber.open(pdf_path) as pdf:\n        text = \"\"\n        for page in pdf.pages:\n            text += page.extract_text()\n    return text\n\ndef chunk_text(text, chunk_size=128, overlap=50):\n    \"\"\"Chunk the text into smaller pieces.\"\"\"\n    sentences = sent_tokenize(text)\n    chunks = []\n    current_chunk = []\n    current_length = 0\n\n    for sentence in sentences:\n        sentence_tokens = tokenizer.tokenize(sentence)\n        sentence_length = len(sentence_tokens)\n\n        if current_length + sentence_length > chunk_size:\n            chunks.append(\" \".join(current_chunk))\n            current_chunk = current_chunk[-overlap:]  # Maintain overlap\n            current_length = len(current_chunk)\n\n        current_chunk.extend(sentence_tokens)\n        current_length += sentence_length\n\n    if current_chunk:\n        chunks.append(\" \".join(current_chunk))\n\n    return chunks\n\ndef process_pdfs_in_directory(directory_path):\n    \"\"\"Extract and chunk text from all PDFs in a directory.\"\"\"\n    all_chunks = []\n\n    for filename in os.listdir(directory_path):\n        if filename.endswith(\".pdf\"):\n            pdf_path = os.path.join(directory_path, filename)\n            print(f\"Processing {filename}...\")\n\n            # Extract text from the PDF\n            text = extract_text_from_pdf(pdf_path)\n\n            # Chunk the extracted text\n            chunks = chunk_text(text, chunk_size=128, overlap=20)\n            all_chunks.extend(chunks)\n\n    return all_chunks","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vu0UNymxze9m","outputId":"32b2d6ac-ba75-4acb-ecf3-e8b09fa3691c","execution":{"iopub.status.busy":"2024-08-10T04:51:24.038642Z","iopub.execute_input":"2024-08-10T04:51:24.038996Z","iopub.status.idle":"2024-08-10T04:51:28.095596Z","shell.execute_reply.started":"2024-08-10T04:51:24.038963Z","shell.execute_reply":"2024-08-10T04:51:28.094606Z"},"trusted":true},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d45daec901bf44d2aa093c888e6f6d13"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"43701cda4914462088662265ceb3d15f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b5343f36eaee42afbdac0853d7134303"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"585777816f3449d2bd7144812b99c7a1"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ff699fd3661d4c6c956554f4fef9011e"}},"metadata":{}},{"name":"stderr","text":"A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n","output_type":"stream"}]},{"cell_type":"code","source":"directory_path = \"/kaggle/input/pdfsdata/\"\nchunks = process_pdfs_in_directory(directory_path)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"x3D_eVVUi-lx","outputId":"73a9e66f-7a8c-468c-95f7-c2a918993230","execution":{"iopub.status.busy":"2024-08-10T04:51:28.096995Z","iopub.execute_input":"2024-08-10T04:51:28.097665Z","iopub.status.idle":"2024-08-10T04:53:07.869116Z","shell.execute_reply.started":"2024-08-10T04:51:28.097623Z","shell.execute_reply":"2024-08-10T04:53:07.868352Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Processing SOC-2018-web-2.pdf...\nProcessing PPEA2023053.pdf...\n","output_type":"stream"},{"name":"stderr","text":"Token indices sequence length is longer than the specified maximum sequence length for this model (564 > 512). Running this sequence through the model will result in indexing errors\n","output_type":"stream"},{"name":"stdout","text":"Processing Consult Paper on the Proposed AMLCFT Notice for Organised Market Operators.pdf...\nProcessing PPEA2020011.pdf...\nProcessing National-Strategy-to-Counter-Illicit-Financev2-2.pdf...\nProcessing 007-article-A001-en.pdf...\nProcessing ASEAN-Plan-of-Action-in-Combating-TC_Adopted-by-11th-AMMTC-on-20Sept17.pdf...\nProcessing AML_CFT (1).pdf...\n","output_type":"stream"}]},{"cell_type":"code","source":"def get_embedding(text):\n    ''' Convert text chunk into an embedding to put into the faiss index'''\n    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True).to(device)\n    outputs = model(**inputs)\n    embedding = outputs.last_hidden_state.mean(dim=1).cpu().detach().numpy()\n\n    return embedding\n\n# Generate embeddings for all chunks\nchunk_embeddings = [get_embedding(chunk) for chunk in chunks]","metadata":{"id":"ihygGhbXlsyl","execution":{"iopub.status.busy":"2024-08-10T04:53:15.745279Z","iopub.execute_input":"2024-08-10T04:53:15.745765Z","iopub.status.idle":"2024-08-10T04:53:34.419924Z","shell.execute_reply.started":"2024-08-10T04:53:15.745733Z","shell.execute_reply":"2024-08-10T04:53:34.419140Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# Initialize FAISS index\nd = 768  # Dimension of the BERT embeddings\nindex = faiss.IndexFlatL2(d)\n\nchunk_embeddings_array = np.vstack(chunk_embeddings)\n\nindex.add(np.array(chunk_embeddings_array, dtype='float32'))\n\ndef retrieve_chunks(query, k=5):\n    '''Retrieve the most similar chunks to the query for context'''\n    # Generate embedding for the query using the correct tokenizer\n    inputs = tokenizer(query, return_tensors=\"pt\")\n    query_embedding = model(**inputs).pooler_output.detach().numpy()\n\n    # Reshape query_embedding to match the shape required by FAISS (1, d)\n    query_embedding = np.array(query_embedding, dtype='float32').reshape(1, -1)\n\n    # Retrieve the top-k relevant chunk indices from FAISS\n    D, I = index.search(query_embedding, k)\n\n    # Extract the actual chunks using the indices retrieved from FAISS\n    retrieved_chunks = [chunks[i] for i in I[0]]\n    return retrieved_chunks","metadata":{"id":"Bi5SunAPThf7","execution":{"iopub.status.busy":"2024-08-10T04:54:10.614146Z","iopub.execute_input":"2024-08-10T04:54:10.614896Z","iopub.status.idle":"2024-08-10T04:54:10.633100Z","shell.execute_reply.started":"2024-08-10T04:54:10.614860Z","shell.execute_reply":"2024-08-10T04:54:10.632270Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# Load the tokenizer and model\ntokenizer_llm = AutoTokenizer.from_pretrained(\"google/gemma-2-2b-it\")\nmodel_llm = AutoModelForCausalLM.from_pretrained(\"google/gemma-2-2b-it\")\n\n# Initialize the pipeline with the model and tokenizer\ntext_generation_pipeline = pipeline(\n    \"text-generation\",\n    model=model_llm,\n    tokenizer=tokenizer_llm,\n    device = device\n)\n\ndef generate_answer(query, retrieved_chunks):\n    # Combine retrieved chunks into a context string\n    context = \" Context:\".join(retrieved_chunks)\n\n    query_with_context = query + context\n\n    # Use the pipeline to generate an answer\n    output = text_generation_pipeline(query_with_context, max_new_tokens=256)\n\n    # Extract the generated text\n    answer = output[0][\"generated_text\"]\n\n    return answer\n","metadata":{"id":"MSwgVQ5bnyFK","execution":{"iopub.status.busy":"2024-08-10T04:54:13.957797Z","iopub.execute_input":"2024-08-10T04:54:13.958635Z"},"trusted":true},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/47.0k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"85a9130319fe4317b11bb9506d3f65c4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/4.24M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3f956b4edf6c4f8dbb69e69d008e744e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/17.5M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"002cad8895e6424a9205235ccd4d4840"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/636 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2c709b08f3524d51a9f2d6b5fa0d7a19"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/838 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"591d63e0b6b547109c10147569f021e3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/24.2k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"88fa53c6cdfd400babe7cd3eebd8e79d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e7333307d6a04526846d31ecaa3aa3cb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00002.safetensors:   0%|          | 0.00/4.99G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"944edfa051914dca9da313bc1af4d192"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00002.safetensors:   0%|          | 0.00/241M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c8152b74086c488e91d7b0788a35d280"}},"metadata":{}}]},{"cell_type":"code","source":"query = \"Tell me what other countries are doing for money laundering/illicit finance\"\nretrieved_chunks = retrieve_chunks(query, k=4)\nretrieved_chunks","metadata":{"execution":{"iopub.status.busy":"2024-08-10T04:38:42.971998Z","iopub.execute_input":"2024-08-10T04:38:42.972521Z","iopub.status.idle":"2024-08-10T04:38:43.092124Z","shell.execute_reply.started":"2024-08-10T04:38:42.972472Z","shell.execute_reply":"2024-08-10T04:38:43.090863Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"['its global network of missions to help drive progress to address modern slavery and human trafficking in different regions . in september 2017 , the prime minister , world leaders and the united nations ( un ) secretary general launched a ‘ call to action to end forced labour , modern slavery and human trafficking ’ at the un general assembly , which over 80 countries have now endorsed . 178 we will continue to build our bilateral relationships with the key source countries whose nationals present most frequently in the uk , as well as work with countries where there is a high global incidence of slavery .',\n ') will support fast , ‘ secure ’ and anonymous operating environments that facilitate all levels of criminal ##ity . the increasingly per ##vas ##ive nature of these technologies will allow less skilled and resource ##d criminals to gain access to markets and tools that were previously out of their reach . 30 national crime agency , ‘ national strategic assessment of serious and organised crime 2018 ’ . 31 department for digital , culture , media and sport , ‘ cyber security breach ##es survey 2018 ’ , april 2018 .',\n 'particularly their direct victims , suffer the consequences . protecting the public is my highest priority as home secretary . this strategy sets out the government ’ s approach to prevent and defend against serious and organised crime in all its forms , and our un ##yi ##eld ##ing endeavour to track down perpetrators , from child sex offenders to corrupt elites , to bring them to justice . we will allow no safe space for these people , their networks or their illicit money in our society . following the publication of the previous serious and organised crime strategy in 2013 , we have made significant progress in creating the powers , partnerships and law enforcement structures we need to respond to the threat .',\n 'artificial intelligence ) . 187 we will ensure the private sector is integrated into our response to specific threats . in the waste sector , for example , the environment agency is setting up an intelligence sharing concord ##at with the industry to tackle illegal waste carriers . we will also expand our engagement with the private sector beyond specific sectors , to broad ##en collaboration on cross - cutting threats and design out vu ##ln ##era ##bilities . at the local level , the serious and organised crime community coordinator ##s will seek to integrate local business associations , and local enterprise partnerships in england , as part of the multi - agency response within communities .']"},"metadata":{}}]},{"cell_type":"code","source":"# Example query\nquery = \"What are the most effective countermeasures against money laundering that uses financial instruments?\"\nretrieved_chunks = retrieve_chunks(query, k=3)\nanswer = generate_answer(query, retrieved_chunks)\n\nprint(\"Answer:\", answer)","metadata":{"id":"xygNLfTYVD9H","execution":{"iopub.status.busy":"2024-08-10T04:32:28.289190Z","iopub.execute_input":"2024-08-10T04:32:28.289633Z","iopub.status.idle":"2024-08-10T04:35:34.916539Z","shell.execute_reply.started":"2024-08-10T04:32:28.289600Z","shell.execute_reply":"2024-08-10T04:35:34.914723Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Answer: What are the most effective countermeasures against money laundering that uses financial instruments?its global network of missions to help drive progress to address modern slavery and human trafficking in different regions . in september 2017 , the prime minister , world leaders and the united nations ( un ) secretary general launched a ‘ call to action to end forced labour , modern slavery and human trafficking ’ at the un general assembly , which over 80 countries have now endorsed . 178 we will continue to build our bilateral relationships with the key source countries whose nationals present most frequently in the uk , as well as work with countries where there is a high global incidence of slavery . Context:particularly their direct victims , suffer the consequences . protecting the public is my highest priority as home secretary . this strategy sets out the government ’ s approach to prevent and defend against serious and organised crime in all its forms , and our un ##yi ##eld ##ing endeavour to track down perpetrators , from child sex offenders to corrupt elites , to bring them to justice . we will allow no safe space for these people , their networks or their illicit money in our society . following the publication of the previous serious and organised crime strategy in 2013 , we have made significant progress in creating the powers , partnerships and law enforcement structures we need to respond to the threat . Context:associations , and local enterprise partnerships in england , as part of the multi - agency response within communities . at the national level , we will create a dedicated hub within the home office to provide a focal point for the department ’ s work with the private sector on a wide range of crime types , including serious and organised crime . at the international level , we will look to set the global agenda on public - private partnerships . we will promote the uk model internationally through soc ##net , sharing best practice ( particularly on engaging with the financial sector ) and standard ##ising public - private partnerships as an approach ( i . e ., the uk model ). \n\nThe provided text discusses efforts to combat modern slavery and human trafficking, as well as serious and organized crime. It does not directly address money laundering using financial instruments. \n\nTo address your question about countermeasures against money laundering using financial instruments, here are some key strategies and tools:\n\n**1. Enhanced Know Your Customer (KYC) and Anti-Money Laundering (AML) Regulations:**\n\n* **Stricter KYC requirements:** Financial institutions must verify the identity of their customers and understand the source of their funds.\n* **Enhanced AML compliance:** Institutions must implement robust AML programs, including risk assessments, transaction monitoring, and suspicious activity reporting.\n* **Data sharing:** Collaboration between financial institutions and law enforcement agencies to share information about suspicious transactions.\n\n**2. Financial Intelligence Units (FIUs):**\n\n* **Centralized information gathering:** FIUs collect and analyze financial data to identify suspicious activities and potential money laundering schemes.\n* **International cooperation:** FIUs collaborate with counterparts in other countries to share information and track down criminals.\n\n**3. Regulatory and Enforcement Actions:**\n\n* **Increased penalties:** Financial institutions that fail to comply with AML regulations face significant fines and penalties.\n* **Asset forfeiture:** Authorities\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}